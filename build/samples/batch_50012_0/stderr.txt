Generator random_pipeline has base_path /home/chamika2/upstream/halide-data/build/samples/batch_50012_0/random_pipeline
compile_multitarget: single target is x86-64-linux-avx-avx2-avx512-avx512_cannonlake-avx512_sapphirerapids-avx512_skylake-f16c-fma-no_runtime-sse41
(let t6 = all_r$1(_0, _1, _2) in (let t7 = conv_r__1(_0, _1, _2) in ((max(t6, t7)*t7) <= (select(t7 == 0, 0, 1) + t6))))
In random expression: (let t10 = sliced(_0 + -2, _1 + -1, 0) in (int32(uint8(max(sliced(_0 + -1, _1, 0), sliced(_0 + -4, _1 + -4, 0)*t10))) < select(t10 < sliced(_0, _1 + -2, 0), min(sliced(_0 + -2, _1 + -3, 0), sliced(_0, _1, 0)), sliced(_0, _1 + -1, 0))))
The following expressions were unused:
sliced(_0, _1 + -4, 0)
sliced(_0, _1 + -3, 0)
sliced(_0 + -4, _1, 0)
sliced(_0 + -4, _1 + -3, 0)
sliced(_0 + -4, _1 + -2, 0)
sliced(_0 + -4, _1 + -1, 0)
sliced(_0 + -3, _1, 0)
sliced(_0 + -3, _1 + -4, 0)
sliced(_0 + -3, _1 + -3, 0)
sliced(_0 + -3, _1 + -2, 0)
sliced(_0 + -3, _1 + -1, 0)
sliced(_0 + -2, _1, 0)
sliced(_0 + -2, _1 + -4, 0)
sliced(_0 + -2, _1 + -2, 0)
sliced(_0 + -1, _1 + -4, 0)
sliced(_0 + -1, _1 + -3, 0)
sliced(_0 + -1, _1 + -2, 0)
sliced(_0 + -1, _1 + -1, 0)
In random expression: (int32(((sliced(_0, _1 + -4, 0)*sliced(_0 + -4, _1 + -3, 0)) <= min(sliced(_0 + -1, _1 + -4, 0), sliced(_0 + -2, _1 + -2, 0)))) % (sliced(_0 + -4, _1 + -2, 0) % sliced(_0 + -2, _1 + -3, 0)))
The following expressions were unused:
sliced(_0, _1, 0)
sliced(_0, _1 + -3, 0)
sliced(_0, _1 + -2, 0)
sliced(_0, _1 + -1, 0)
sliced(_0 + -4, _1, 0)
sliced(_0 + -4, _1 + -4, 0)
sliced(_0 + -4, _1 + -1, 0)
sliced(_0 + -3, _1, 0)
sliced(_0 + -3, _1 + -4, 0)
sliced(_0 + -3, _1 + -3, 0)
sliced(_0 + -3, _1 + -2, 0)
sliced(_0 + -3, _1 + -1, 0)
sliced(_0 + -2, _1, 0)
sliced(_0 + -2, _1 + -4, 0)
sliced(_0 + -2, _1 + -1, 0)
sliced(_0 + -1, _1, 0)
sliced(_0 + -1, _1 + -3, 0)
sliced(_0 + -1, _1 + -2, 0)
sliced(_0 + -1, _1 + -1, 0)
In random expression: (let t11 = sliced(_0 + -2, _1 + -3, 0) in max(t11 % sliced(_0, _1 + -3, 0), max(sliced(_0, _1, 0), t11) - sliced(_0 + -1, _1, 0)))
The following expressions were unused:
sliced(_0, _1 + -4, 0)
sliced(_0, _1 + -2, 0)
sliced(_0, _1 + -1, 0)
sliced(_0 + -4, _1, 0)
sliced(_0 + -4, _1 + -4, 0)
sliced(_0 + -4, _1 + -3, 0)
sliced(_0 + -4, _1 + -2, 0)
sliced(_0 + -4, _1 + -1, 0)
sliced(_0 + -3, _1, 0)
sliced(_0 + -3, _1 + -4, 0)
sliced(_0 + -3, _1 + -3, 0)
sliced(_0 + -3, _1 + -2, 0)
sliced(_0 + -3, _1 + -1, 0)
sliced(_0 + -2, _1, 0)
sliced(_0 + -2, _1 + -4, 0)
sliced(_0 + -2, _1 + -2, 0)
sliced(_0 + -2, _1 + -1, 0)
sliced(_0 + -1, _1 + -4, 0)
sliced(_0 + -1, _1 + -3, 0)
sliced(_0 + -1, _1 + -2, 0)
sliced(_0 + -1, _1 + -1, 0)
In random expression: uint16((int32(int8((int32((sliced(_0 + -2, _1 + -1, 0) != sliced(_0 + -4, _1 + -4, 0))) % sliced(_0 + -3, _1 + -1, 0)))) % (sliced(_0 + -2, _1 + -4, 0)*sliced(_0 + -3, _1 + -2, 0))))
The following expressions were unused:
sliced(_0, _1, 0)
sliced(_0, _1 + -4, 0)
sliced(_0, _1 + -3, 0)
sliced(_0, _1 + -2, 0)
sliced(_0, _1 + -1, 0)
sliced(_0 + -4, _1, 0)
sliced(_0 + -4, _1 + -3, 0)
sliced(_0 + -4, _1 + -2, 0)
sliced(_0 + -4, _1 + -1, 0)
sliced(_0 + -3, _1, 0)
sliced(_0 + -3, _1 + -4, 0)
sliced(_0 + -3, _1 + -3, 0)
sliced(_0 + -2, _1, 0)
sliced(_0 + -2, _1 + -3, 0)
sliced(_0 + -2, _1 + -2, 0)
sliced(_0 + -1, _1, 0)
sliced(_0 + -1, _1 + -4, 0)
sliced(_0 + -1, _1 + -3, 0)
sliced(_0 + -1, _1 + -2, 0)
sliced(_0 + -1, _1 + -1, 0)
In random expression: (let t12 = sliced(_0 + -4, _1, 0) in (min(sliced(_0 + -1, _1 + -2, 0) + sliced(_0 + -3, _1 + -2, 0), t12) + (sliced(_0 + -4, _1 + -3, 0)/t12)))
The following expressions were unused:
sliced(_0, _1, 0)
sliced(_0, _1 + -4, 0)
sliced(_0, _1 + -3, 0)
sliced(_0, _1 + -2, 0)
sliced(_0, _1 + -1, 0)
sliced(_0 + -4, _1 + -4, 0)
sliced(_0 + -4, _1 + -2, 0)
sliced(_0 + -4, _1 + -1, 0)
sliced(_0 + -3, _1, 0)
sliced(_0 + -3, _1 + -4, 0)
sliced(_0 + -3, _1 + -3, 0)
sliced(_0 + -3, _1 + -1, 0)
sliced(_0 + -2, _1, 0)
sliced(_0 + -2, _1 + -4, 0)
sliced(_0 + -2, _1 + -3, 0)
sliced(_0 + -2, _1 + -2, 0)
sliced(_0 + -2, _1 + -1, 0)
sliced(_0 + -1, _1, 0)
sliced(_0 + -1, _1 + -4, 0)
sliced(_0 + -1, _1 + -3, 0)
sliced(_0 + -1, _1 + -1, 0)
In random expression: (let t13 = sliced(_0, _1 + -3, 0) in min(max(sliced(_0 + -2, _1 + -4, 0), t13), sliced(_0 + -3, _1, 0) + (t13 - sliced(_0 + -1, _1 + -3, 0))))
The following expressions were unused:
sliced(_0, _1, 0)
sliced(_0, _1 + -4, 0)
sliced(_0, _1 + -2, 0)
sliced(_0, _1 + -1, 0)
sliced(_0 + -4, _1, 0)
sliced(_0 + -4, _1 + -4, 0)
sliced(_0 + -4, _1 + -3, 0)
sliced(_0 + -4, _1 + -2, 0)
sliced(_0 + -4, _1 + -1, 0)
sliced(_0 + -3, _1 + -4, 0)
sliced(_0 + -3, _1 + -3, 0)
sliced(_0 + -3, _1 + -2, 0)
sliced(_0 + -3, _1 + -1, 0)
sliced(_0 + -2, _1, 0)
sliced(_0 + -2, _1 + -3, 0)
sliced(_0 + -2, _1 + -2, 0)
sliced(_0 + -2, _1 + -1, 0)
sliced(_0 + -1, _1, 0)
sliced(_0 + -1, _1 + -4, 0)
sliced(_0 + -1, _1 + -2, 0)
sliced(_0 + -1, _1 + -1, 0)
In random expression: (let t14 = sliced(_0 + -1, _1 + -3, 0) in (let t15 = sliced(_0 + -2, _1 + -2, 0) in (((t14*2) <= (sliced(_0 + -3, _1 + -3, 0)*t15)) && (t15 <= sliced(_0, _1 + -3, 0)))))
The following expressions were unused:
sliced(_0, _1, 0)
sliced(_0, _1 + -4, 0)
sliced(_0, _1 + -2, 0)
sliced(_0, _1 + -1, 0)
sliced(_0 + -4, _1, 0)
sliced(_0 + -4, _1 + -4, 0)
sliced(_0 + -4, _1 + -3, 0)
sliced(_0 + -4, _1 + -2, 0)
sliced(_0 + -4, _1 + -1, 0)
sliced(_0 + -3, _1, 0)
sliced(_0 + -3, _1 + -4, 0)
sliced(_0 + -3, _1 + -2, 0)
sliced(_0 + -3, _1 + -1, 0)
sliced(_0 + -2, _1, 0)
sliced(_0 + -2, _1 + -4, 0)
sliced(_0 + -2, _1 + -3, 0)
sliced(_0 + -2, _1 + -1, 0)
sliced(_0 + -1, _1, 0)
sliced(_0 + -1, _1 + -4, 0)
sliced(_0 + -1, _1 + -2, 0)
sliced(_0 + -1, _1 + -1, 0)
In random expression: (int32(uint16(int8((sliced(_0 + -2, _1, 0) + max(sliced(_0 + -1, _1 + -4, 0), sliced(_0 + -2, _1 + -3, 0))))))/(sliced(_0 + -3, _1 + -1, 0) - sliced(_0 + -1, _1 + -2, 0)))
The following expressions were unused:
sliced(_0, _1, 0)
sliced(_0, _1 + -4, 0)
sliced(_0, _1 + -3, 0)
sliced(_0, _1 + -2, 0)
sliced(_0, _1 + -1, 0)
sliced(_0 + -4, _1, 0)
sliced(_0 + -4, _1 + -4, 0)
sliced(_0 + -4, _1 + -3, 0)
sliced(_0 + -4, _1 + -2, 0)
sliced(_0 + -4, _1 + -1, 0)
sliced(_0 + -3, _1, 0)
sliced(_0 + -3, _1 + -4, 0)
sliced(_0 + -3, _1 + -3, 0)
sliced(_0 + -3, _1 + -2, 0)
sliced(_0 + -2, _1 + -4, 0)
sliced(_0 + -2, _1 + -2, 0)
sliced(_0 + -2, _1 + -1, 0)
sliced(_0 + -1, _1, 0)
sliced(_0 + -1, _1 + -3, 0)
sliced(_0 + -1, _1 + -1, 0)
In random expression: ((max(sliced(_0 + -2, _1, 0), sliced(_0 + -4, _1 + -2, 0))/sliced(_0 + -3, _1 + -3, 0))*(sliced(_0 + -4, _1 + -4, 0) + sliced(_0 + -4, _1, 0)))
The following expressions were unused:
sliced(_0, _1, 0)
sliced(_0, _1 + -4, 0)
sliced(_0, _1 + -3, 0)
sliced(_0, _1 + -2, 0)
sliced(_0, _1 + -1, 0)
sliced(_0 + -4, _1 + -3, 0)
sliced(_0 + -4, _1 + -1, 0)
sliced(_0 + -3, _1, 0)
sliced(_0 + -3, _1 + -4, 0)
sliced(_0 + -3, _1 + -2, 0)
sliced(_0 + -3, _1 + -1, 0)
sliced(_0 + -2, _1 + -4, 0)
sliced(_0 + -2, _1 + -3, 0)
sliced(_0 + -2, _1 + -2, 0)
sliced(_0 + -2, _1 + -1, 0)
sliced(_0 + -1, _1, 0)
sliced(_0 + -1, _1 + -4, 0)
sliced(_0 + -1, _1 + -3, 0)
sliced(_0 + -1, _1 + -2, 0)
sliced(_0 + -1, _1 + -1, 0)
In random expression: ((sliced(_0 + -1, _1 + -4, 0) + max(sliced(_0 + -1, _1, 0), sliced(_0 + -2, _1 + -2, 0))) - min(sliced(_0, _1, 0), sliced(_0 + -2, _1 + -4, 0)))
The following expressions were unused:
sliced(_0, _1 + -4, 0)
sliced(_0, _1 + -3, 0)
sliced(_0, _1 + -2, 0)
sliced(_0, _1 + -1, 0)
sliced(_0 + -4, _1, 0)
sliced(_0 + -4, _1 + -4, 0)
sliced(_0 + -4, _1 + -3, 0)
sliced(_0 + -4, _1 + -2, 0)
sliced(_0 + -4, _1 + -1, 0)
sliced(_0 + -3, _1, 0)
sliced(_0 + -3, _1 + -4, 0)
sliced(_0 + -3, _1 + -3, 0)
sliced(_0 + -3, _1 + -2, 0)
sliced(_0 + -3, _1 + -1, 0)
sliced(_0 + -2, _1, 0)
sliced(_0 + -2, _1 + -3, 0)
sliced(_0 + -2, _1 + -1, 0)
sliced(_0 + -1, _1 + -3, 0)
sliced(_0 + -1, _1 + -2, 0)
sliced(_0 + -1, _1 + -1, 0)
(((((((((((((((((((((((((0 + sliced(_0 + -4, _1 + -4, 0)) + sliced(_0 + -4, _1 + -3, 0)) + sliced(_0 + -4, _1 + -2, 0)) + sliced(_0 + -4, _1 + -1, 0)) + sliced(_0 + -4, _1, 0)) + sliced(_0 + -3, _1 + -4, 0)) + sliced(_0 + -3, _1 + -3, 0)) + sliced(_0 + -3, _1 + -2, 0)) + sliced(_0 + -3, _1 + -1, 0)) + sliced(_0 + -3, _1, 0)) + sliced(_0 + -2, _1 + -4, 0)) + sliced(_0 + -2, _1 + -3, 0)) + sliced(_0 + -2, _1 + -2, 0)) + sliced(_0 + -2, _1 + -1, 0)) + sliced(_0 + -2, _1, 0)) + sliced(_0 + -1, _1 + -4, 0)) + sliced(_0 + -1, _1 + -3, 0)) + sliced(_0 + -1, _1 + -2, 0)) + sliced(_0 + -1, _1 + -1, 0)) + sliced(_0 + -1, _1, 0)) + sliced(_0, _1 + -4, 0)) + sliced(_0, _1 + -3, 0)) + sliced(_0, _1 + -2, 0)) + sliced(_0, _1 + -1, 0)) + sliced(_0, _1, 0))
In random expression: (uint1)1
The following expressions were unused:
conv_w__0(_0, _1, _2)
conv_w__0(_0 + -1, _1, _2)
(conv_w__0(_0, _1, _2)*conv_w__0(_0 + -1, _1, _2))
(let t29 = all_r$4(_0, _1, _2) in uint16(((t29 % conv_r__1(_0, _1, _2))/t29)))
(let t33 = upsampled_nn__1(_0, _1, _2) in (let t34 = upsampled_nn__1$1(_0, _1, _2) in min(min(t33, t34), (t33*t34)*t34)))
Applying autoscheduler (NONE) to Generator random_pipeline ...
Creating initial loop nests...
Injecting realization of { casted }
Injecting realization of { relu$1 }
Injecting realization of { conv_r__1$1 }
Injecting realization of { binary_op }
Injecting realization of { all_r$1 }
Injecting realization of { sliced }
Injecting realization of { all_r }
Injecting realization of { conv_r__1 }
Inlining constant_exterior
Inlining repeat_edge
Inlining lambda_0
Inlining input_im
Skipping injecting memoization...
Injecting tracing...
Adding checks for parameters
Computing bounds of each function's value
Clamping unsafe data-dependent accesses
Performing computation bounds inference...
Removing extern loops...
Performing sliding window optimization...
Uniquifying variable names...
Simplifying...
Simplifying correlated differences...
Performing allocation bounds inference...
Adding checks for images
Removing code that depends on undef values...
Performing storage folding optimization...
Injecting debug_to_file calls...
Injecting prefetches...
Discarding safe promises...
Dynamically skipping stages...
Forking asynchronous producers...
Destructuring tuple-valued realizations...
Bounding small realizations...
Performing storage flattening...
Adding atomic mutex allocation...
Unpacking buffer arguments...
Skipping rewriting memoized allocations...
Simplifying...
Reduce prefetch dimension...
Simplifying correlated differences...
Unrolling...
Vectorizing...
Detecting vector interleavings...
Partitioning loops to simplify boundary conditions...
Staging strided loads...
Trimming loops to the region over which they do something...
Rebasing loops to zero...
Hoisting loop invariant if statements...
Injecting early frees...
Simplifying correlated differences...
Bounding small allocations...
Simplifying...
Lowering unsafe promises...
Extracting tile operations...
Flattening nested ramps...
Removing dead allocations and moving loop invariant code...
Finding intrinsics...
Hoisting prefetches...
Lowering after final simplification:
assert(reinterpret<uint64>((struct halide_buffer_t *)input.buffer) != (uint64)0, halide_error_buffer_argument_is_null("input"))
assert(reinterpret<uint64>((struct halide_buffer_t *)casted.buffer) != (uint64)0, halide_error_buffer_argument_is_null("casted"))
let casted = (void *)_halide_buffer_get_host((struct halide_buffer_t *)casted.buffer)
let casted.type = (uint32)_halide_buffer_get_type((struct halide_buffer_t *)casted.buffer)
let casted.device_dirty = (uint1)_halide_buffer_get_device_dirty((struct halide_buffer_t *)casted.buffer)
let casted.dimensions = _halide_buffer_get_dimensions((struct halide_buffer_t *)casted.buffer)
let casted.min.0 = _halide_buffer_get_min((struct halide_buffer_t *)casted.buffer, 0)
let casted.extent.0 = _halide_buffer_get_extent((struct halide_buffer_t *)casted.buffer, 0)
let casted.stride.0 = _halide_buffer_get_stride((struct halide_buffer_t *)casted.buffer, 0)
let casted.min.1 = _halide_buffer_get_min((struct halide_buffer_t *)casted.buffer, 1)
let casted.extent.1 = _halide_buffer_get_extent((struct halide_buffer_t *)casted.buffer, 1)
let casted.stride.1 = _halide_buffer_get_stride((struct halide_buffer_t *)casted.buffer, 1)
let casted.min.2 = _halide_buffer_get_min((struct halide_buffer_t *)casted.buffer, 2)
let casted.extent.2 = _halide_buffer_get_extent((struct halide_buffer_t *)casted.buffer, 2)
let casted.stride.2 = _halide_buffer_get_stride((struct halide_buffer_t *)casted.buffer, 2)
let input = (void *)_halide_buffer_get_host((struct halide_buffer_t *)input.buffer)
let input.type = (uint32)_halide_buffer_get_type((struct halide_buffer_t *)input.buffer)
let input.device_dirty = (uint1)_halide_buffer_get_device_dirty((struct halide_buffer_t *)input.buffer)
let input.dimensions = _halide_buffer_get_dimensions((struct halide_buffer_t *)input.buffer)
let input.min.0 = _halide_buffer_get_min((struct halide_buffer_t *)input.buffer, 0)
let input.extent.0 = _halide_buffer_get_extent((struct halide_buffer_t *)input.buffer, 0)
let input.stride.0 = _halide_buffer_get_stride((struct halide_buffer_t *)input.buffer, 0)
let input.min.1 = _halide_buffer_get_min((struct halide_buffer_t *)input.buffer, 1)
let input.extent.1 = _halide_buffer_get_extent((struct halide_buffer_t *)input.buffer, 1)
let input.stride.1 = _halide_buffer_get_stride((struct halide_buffer_t *)input.buffer, 1)
let input.min.2 = _halide_buffer_get_min((struct halide_buffer_t *)input.buffer, 2)
let input.extent.2 = _halide_buffer_get_extent((struct halide_buffer_t *)input.buffer, 2)
let input.stride.2 = _halide_buffer_get_stride((struct halide_buffer_t *)input.buffer, 2)
let input.extent.0.required = let t138 = (input.extent.0 + input.min.0) in (max(min(casted.extent.0 + casted.min.0, t138), input.min.0 + 1) - max(min(t138 + -1, casted.min.0), input.min.0))
let input.min.0.required = max(min((input.extent.0 + input.min.0) + -1, casted.min.0), input.min.0)
let input.extent.1.required = let t139 = (input.extent.1 + input.min.1) in (max(min((casted.extent.1 + casted.min.1) + 14, t139), input.min.1 + 1) - max(min(min(t139 + 16, casted.min.1), min(t139 + 8, casted.min.1) + 8) + -17, input.min.1))
let input.min.1.required = let t140 = (input.extent.1 + input.min.1) in max(min(min(t140 + 16, casted.min.1), min(t140 + 8, casted.min.1) + 8) + -17, input.min.1)
let input.extent.2.required = let t141 = (input.extent.2 + input.min.2) in (max(min(max(casted.extent.2 + casted.min.2, 3), t141), input.min.2 + 1) - max(min(min(t141, 1) + -1, casted.min.2), input.min.2))
let input.min.2.required = max(min(min(input.extent.2 + input.min.2, 1) + -1, casted.min.2), input.min.2)
if ((uint1)_halide_buffer_is_bounds_query((struct halide_buffer_t *)casted.buffer)) {
 (struct halide_buffer_t *)_halide_buffer_init((struct halide_buffer_t *)casted.buffer, (struct halide_dimension_t *)_halide_buffer_get_shape((struct halide_buffer_t *)casted.buffer), reinterpret<(void *)>((uint64)0), (uint64)0, reinterpret<(struct halide_device_interface_t *)>((uint64)0), 0, 32, 3, (struct halide_dimension_t *)make_struct(casted.min.0, casted.extent.0, 1, 0, casted.min.1, casted.extent.1, casted.extent.0, 0, casted.min.2, casted.extent.2, casted.extent.0*casted.extent.1, 0), (uint64)0)
}
if ((uint1)_halide_buffer_is_bounds_query((struct halide_buffer_t *)input.buffer)) {
 (struct halide_buffer_t *)_halide_buffer_init((struct halide_buffer_t *)input.buffer, (struct halide_dimension_t *)_halide_buffer_get_shape((struct halide_buffer_t *)input.buffer), reinterpret<(void *)>((uint64)0), (uint64)0, reinterpret<(struct halide_device_interface_t *)>((uint64)0), 0, 32, 3, (struct halide_dimension_t *)make_struct(input.min.0.required, input.extent.0.required, 1, 0, input.min.1.required, input.extent.1.required, input.extent.0.required, 0, input.min.2.required, input.extent.2.required, input.extent.0.required*input.extent.1.required, 0), (uint64)0)
}
if (!((uint1)_halide_buffer_is_bounds_query((struct halide_buffer_t *)casted.buffer) || (uint1)_halide_buffer_is_bounds_query((struct halide_buffer_t *)input.buffer))) {
 assert(casted.type == (uint32)73728, halide_error_bad_type("Output buffer casted", casted.type, (uint32)73728))
 assert(casted.dimensions == 3, halide_error_bad_dimensions("Output buffer casted", casted.dimensions, 3))
 assert(input.type == (uint32)73728, halide_error_bad_type("Input buffer input", input.type, (uint32)73728))
 assert(input.dimensions == 3, halide_error_bad_dimensions("Input buffer input", input.dimensions, 3))
 assert(0 <= casted.extent.0, halide_error_buffer_extents_negative("Output buffer casted", 0, casted.extent.0))
 assert(0 <= casted.extent.1, halide_error_buffer_extents_negative("Output buffer casted", 1, casted.extent.1))
 assert(0 <= casted.extent.2, halide_error_buffer_extents_negative("Output buffer casted", 2, casted.extent.2))
 assert((input.min.0 <= input.min.0.required) && ((input.extent.0.required + input.min.0.required) <= (input.extent.0 + input.min.0)), halide_error_access_out_of_bounds("Input buffer input", 0, input.min.0.required, (input.extent.0.required + input.min.0.required) + -1, input.min.0, (input.extent.0 + input.min.0) + -1))
 assert(0 <= input.extent.0, halide_error_buffer_extents_negative("Input buffer input", 0, input.extent.0))
 assert((input.min.1 <= input.min.1.required) && ((input.extent.1.required + input.min.1.required) <= (input.extent.1 + input.min.1)), halide_error_access_out_of_bounds("Input buffer input", 1, input.min.1.required, (input.extent.1.required + input.min.1.required) + -1, input.min.1, (input.extent.1 + input.min.1) + -1))
 assert(0 <= input.extent.1, halide_error_buffer_extents_negative("Input buffer input", 1, input.extent.1))
 assert((input.min.2 <= input.min.2.required) && ((input.extent.2.required + input.min.2.required) <= (input.extent.2 + input.min.2)), halide_error_access_out_of_bounds("Input buffer input", 2, input.min.2.required, (input.extent.2.required + input.min.2.required) + -1, input.min.2, (input.extent.2 + input.min.2) + -1))
 assert(0 <= input.extent.2, halide_error_buffer_extents_negative("Input buffer input", 2, input.extent.2))
 assert(casted.stride.0 == 1, halide_error_constraint_violated("casted.stride.0", casted.stride.0, "1", 1))
 assert(input.stride.0 == 1, halide_error_constraint_violated("input.stride.0", input.stride.0, "1", 1))
 let casted.total_extent.1 = int64(casted.extent.1)*int64(casted.extent.0)
 let casted.total_extent.2 = casted.total_extent.1*int64(casted.extent.2)
 let input.total_extent.1 = int64(input.extent.1)*int64(input.extent.0)
 let input.total_extent.2 = input.total_extent.1*int64(input.extent.2)
 assert(uint64(casted.extent.0) <= (uint64)2147483647, halide_error_buffer_allocation_too_large("casted", uint64(casted.extent.0), (uint64)2147483647))
 assert((uint64)abs(int64(casted.extent.1)*int64(casted.stride.1)) <= (uint64)2147483647, halide_error_buffer_allocation_too_large("casted", (uint64)abs(int64(casted.extent.1)*int64(casted.stride.1)), (uint64)2147483647))
 assert(casted.total_extent.1 <= (int64)2147483647, halide_error_buffer_extents_too_large("casted", casted.total_extent.1, (int64)2147483647))
 assert((uint64)abs(int64(casted.extent.2)*int64(casted.stride.2)) <= (uint64)2147483647, halide_error_buffer_allocation_too_large("casted", (uint64)abs(int64(casted.extent.2)*int64(casted.stride.2)), (uint64)2147483647))
 assert(casted.total_extent.2 <= (int64)2147483647, halide_error_buffer_extents_too_large("casted", casted.total_extent.2, (int64)2147483647))
 assert(uint64(input.extent.0) <= (uint64)2147483647, halide_error_buffer_allocation_too_large("input", uint64(input.extent.0), (uint64)2147483647))
 assert((uint64)abs(int64(input.extent.1)*int64(input.stride.1)) <= (uint64)2147483647, halide_error_buffer_allocation_too_large("input", (uint64)abs(int64(input.extent.1)*int64(input.stride.1)), (uint64)2147483647))
 assert(input.total_extent.1 <= (int64)2147483647, halide_error_buffer_extents_too_large("input", input.total_extent.1, (int64)2147483647))
 assert((uint64)abs(int64(input.extent.2)*int64(input.stride.2)) <= (uint64)2147483647, halide_error_buffer_allocation_too_large("input", (uint64)abs(int64(input.extent.2)*int64(input.stride.2)), (uint64)2147483647))
 assert(input.total_extent.2 <= (int64)2147483647, halide_error_buffer_extents_too_large("input", input.total_extent.2, (int64)2147483647))
 assert(!casted.device_dirty, halide_error_device_dirty_with_no_device_support("Output buffer casted"))
 assert(!input.device_dirty, halide_error_device_dirty_with_no_device_support("Input buffer input"))
 assert(casted != reinterpret<(void *)>((uint64)0), halide_error_host_is_null("Output buffer casted"))
 assert(input != reinterpret<(void *)>((uint64)0), halide_error_host_is_null("Input buffer input"))
 allocate conv_r__1$1[uint8 * casted.extent.0 * casted.extent.1 * casted.extent.2]
 produce conv_r__1$1 {
  for (conv_r__1$1.s0._2.rebased, 0, casted.extent.2) {
   let t123 = (casted.extent.0*casted.extent.1)*conv_r__1$1.s0._2.rebased
   for (conv_r__1$1.s0._1.rebased, 0, casted.extent.1) {
    let t124 = (casted.extent.0*conv_r__1$1.s0._1.rebased) + t123
    for (conv_r__1$1.s0._0.rebased, 0, casted.extent.0) {
     conv_r__1$1[conv_r__1$1.s0._0.rebased + t124] = (uint8)0
    }
   }
  }
  for (conv_r__1$1.s1._2.rebased, 0, casted.extent.2) {
   let t126 = (casted.extent.0*casted.extent.1)*conv_r__1$1.s1._2.rebased
   for (conv_r__1$1.s1._1.rebased, 0, casted.extent.1) {
    let t127 = (casted.extent.0*conv_r__1$1.s1._1.rebased) + t126
    for (conv_r__1$1.s1._0.rebased, 0, casted.extent.0) {
     let t128 = conv_r__1$1.s1._0.rebased + t127
     for (conv_r__1$1.s1.r177$x, 0, 18) {
      conv_r__1$1[t128] = uint8(uint1(conv_r__1$1[t128]))
     }
    }
   }
  }
 }
 allocate relu$1[uint8 * casted.extent.0 * casted.extent.1 * casted.extent.2]
 produce relu$1 {
  consume conv_r__1$1 {
   for (relu$1.s0._2.rebased, 0, casted.extent.2) {
    let t130 = (casted.extent.0*casted.extent.1)*relu$1.s0._2.rebased
    for (relu$1.s0._1.rebased, 0, casted.extent.1) {
     let t131 = (casted.extent.0*relu$1.s0._1.rebased) + t130
     for (relu$1.s0._0.rebased, 0, casted.extent.0) {
      let t117 = relu$1.s0._0.rebased + t131
      relu$1[t117] = uint8(uint1(conv_r__1$1[t117]))
     }
    }
   }
  }
 }
 free conv_r__1$1
 produce casted {
  consume relu$1 {
   let t133 = 0 - ((casted.min.2*casted.stride.2) + (casted.min.1*casted.stride.1))
   for (casted.s0._2.rebased, 0, casted.extent.2) {
    let t134 = (casted.extent.0*casted.extent.1)*casted.s0._2.rebased
    let t135 = ((casted.min.2 + casted.s0._2.rebased)*casted.stride.2) + t133
    for (casted.s0._1.rebased, 0, casted.extent.1) {
     let t137 = ((casted.min.1 + casted.s0._1.rebased)*casted.stride.1) + t135
     let t136 = (casted.extent.0*casted.s0._1.rebased) + t134
     for (casted.s0._0.rebased, 0, casted.extent.0) {
      casted[casted.s0._0.rebased + t137] = int32(uint1(relu$1[casted.s0._0.rebased + t136]))
     }
    }
   }
  }
 }
 free relu$1
}


Skipping Hexagon offload...
Skipping GPU offload...
Lowering Parallel Tasks...
Target triple of initial module: x86_64--linux-gnu
Generating llvm bitcode...
Generating llvm bitcode prolog for function random_pipeline...
Generating llvm bitcode for function random_pipeline...
add_temp_object_file: /tmp/WM0qdJ/random_pipeline.a.o
Module.compile(): temporary object /tmp/WM0qdJ/random_pipeline.a.o
emit_file.Compiling to native code...
Module.compile(): static_library /home/chamika2/upstream/halide-data/build/samples/batch_50012_0/random_pipeline.a
file_unlink: /tmp/WM0qdJ/random_pipeline.a.o
dir_rmdir: /tmp/WM0qdJ
Module.compile(): c_header /home/chamika2/upstream/halide-data/build/samples/batch_50012_0/random_pipeline.h
Module.compile(): registration /home/chamika2/upstream/halide-data/build/samples/batch_50012_0/random_pipeline.registration.cpp
